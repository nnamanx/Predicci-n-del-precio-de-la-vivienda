{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea46cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399e804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('binaaz_train.csv')\n",
    "# test_data = pd.read_csv('binaaz_test.csv')\n",
    "train_data = pd.read_csv('new_train_data.csv')\n",
    "test_data = pd.read_csv('new_test_data.csv')\n",
    "baku_coordinates = pd.read_excel('baku_coordinates.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26abcd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripadvisor_baku['Latitude'], tripadvisor_baku['Longitude'] = (\n",
    "    tripadvisor_baku['Longitude'], tripadvisor_baku['Latitude'])\n",
    "\n",
    "all_popular_places = pd.concat([baku_coordinates, tripadvisor_baku], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a366b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1955624621.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[f'Distance_to_{place_name}'] = distance_series\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>price_currency</th>\n",
       "      <th>poster</th>\n",
       "      <th>poster_type</th>\n",
       "      <th>Ünvan</th>\n",
       "      <th>description</th>\n",
       "      <th>Yeniləndi</th>\n",
       "      <th>Mərtəbə</th>\n",
       "      <th>...</th>\n",
       "      <th>Distance_to_Elmlar Akademiyası</th>\n",
       "      <th>Distance_to_Inshaatchilar</th>\n",
       "      <th>Distance_to_20 Yanvar</th>\n",
       "      <th>Distance_to_Memar Ajami</th>\n",
       "      <th>Distance_to_Nasimi</th>\n",
       "      <th>Distance_to_Azadlig Prospekti</th>\n",
       "      <th>Distance_to_Darnagul</th>\n",
       "      <th>Distance_to_Jafar Jabbarli</th>\n",
       "      <th>Distance_to_Shah Ismail Hatai</th>\n",
       "      <th>Distance_to_Avtovagzal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Satılır 3 otaqlı yeni tikili 135 m², Gənclik m.</td>\n",
       "      <td>300000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Mubariz</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Bakıxanov  küçəsi</td>\n",
       "      <td>Təcili  Satılır...Qaz  Kupça  var..\\nRoseville...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>5 / 17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.160858</td>\n",
       "      <td>4.286099</td>\n",
       "      <td>3.743220</td>\n",
       "      <td>3.426369</td>\n",
       "      <td>3.526779</td>\n",
       "      <td>3.003716</td>\n",
       "      <td>2.935154</td>\n",
       "      <td>2.290520</td>\n",
       "      <td>2.572313</td>\n",
       "      <td>5.369413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Satılır 3 otaqlı yeni tikili 132.5 m², Nəriman...</td>\n",
       "      <td>153000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Самир Ахмедов</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, ул.Табриза 21-23</td>\n",
       "      <td>Срочно.В Наримановском р-не недалеко от 162 шк...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>10 / 16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.641406</td>\n",
       "      <td>4.332380</td>\n",
       "      <td>4.231128</td>\n",
       "      <td>4.144856</td>\n",
       "      <td>4.607402</td>\n",
       "      <td>4.205311</td>\n",
       "      <td>4.055194</td>\n",
       "      <td>1.151950</td>\n",
       "      <td>1.703825</td>\n",
       "      <td>6.151793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 115 m², Bayıl q.</td>\n",
       "      <td>171300</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Fikrət</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Q.Abbasov küçəsi</td>\n",
       "      <td>Səbail rayonu ,Bayıl qəsəbəsi Q.Abbasov küçəsi...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>7 / 14</td>\n",
       "      <td>...</td>\n",
       "      <td>3.581641</td>\n",
       "      <td>5.582994</td>\n",
       "      <td>6.768512</td>\n",
       "      <td>7.300160</td>\n",
       "      <td>8.641321</td>\n",
       "      <td>8.760267</td>\n",
       "      <td>8.923853</td>\n",
       "      <td>3.735953</td>\n",
       "      <td>4.969501</td>\n",
       "      <td>9.007009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 43 m², Masazır q.</td>\n",
       "      <td>44500</td>\n",
       "      <td>AZN</td>\n",
       "      <td>QASIM</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, İstiqlaliyyət 14</td>\n",
       "      <td>Masazır qəsəbəsi, Yeni Bakı yaşayış kompleksi ...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>4 / 8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.206736</td>\n",
       "      <td>12.227296</td>\n",
       "      <td>11.026164</td>\n",
       "      <td>10.643766</td>\n",
       "      <td>9.980590</td>\n",
       "      <td>10.854980</td>\n",
       "      <td>12.221727</td>\n",
       "      <td>15.191301</td>\n",
       "      <td>16.077384</td>\n",
       "      <td>8.774474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 65 m², Memar Əcəm...</td>\n",
       "      <td>89900</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Heydər bəy</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Mir Cəlal küç.</td>\n",
       "      <td>Tecili satilir !!\\n4 cu mikrorayonda, Elmed kl...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>12 / 18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.673150</td>\n",
       "      <td>3.024011</td>\n",
       "      <td>1.442451</td>\n",
       "      <td>0.755332</td>\n",
       "      <td>1.520455</td>\n",
       "      <td>2.857948</td>\n",
       "      <td>4.475584</td>\n",
       "      <td>5.308145</td>\n",
       "      <td>6.452175</td>\n",
       "      <td>1.403696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id                                              title   price  \\\n",
       "0    6    Satılır 3 otaqlı yeni tikili 135 m², Gənclik m.  300000   \n",
       "1   22  Satılır 3 otaqlı yeni tikili 132.5 m², Nəriman...  153000   \n",
       "2   72      Satılır 2 otaqlı yeni tikili 115 m², Bayıl q.  171300   \n",
       "3   76     Satılır 2 otaqlı yeni tikili 43 m², Masazır q.   44500   \n",
       "4   86  Satılır 2 otaqlı yeni tikili 65 m², Memar Əcəm...   89900   \n",
       "\n",
       "  price_currency         poster       poster_type  \\\n",
       "0            AZN        Mubariz  vasitəçi (agent)   \n",
       "1            AZN  Самир Ахмедов  vasitəçi (agent)   \n",
       "2            AZN         Fikrət  vasitəçi (agent)   \n",
       "3            AZN          QASIM  vasitəçi (agent)   \n",
       "4            AZN     Heydər bəy  vasitəçi (agent)   \n",
       "\n",
       "                               Ünvan  \\\n",
       "0   Bakı şəhəri, Bakıxanov  küçəsi     \n",
       "1      Bakı şəhəri, ул.Табриза 21-23   \n",
       "2      Bakı şəhəri, Q.Abbasov küçəsi   \n",
       "3      Bakı şəhəri, İstiqlaliyyət 14   \n",
       "4        Bakı şəhəri, Mir Cəlal küç.   \n",
       "\n",
       "                                         description       Yeniləndi  Mərtəbə  \\\n",
       "0  Təcili  Satılır...Qaz  Kupça  var..\\nRoseville...  05 Fevral 2021   5 / 17   \n",
       "1  Срочно.В Наримановском р-не недалеко от 162 шк...  05 Fevral 2021  10 / 16   \n",
       "2  Səbail rayonu ,Bayıl qəsəbəsi Q.Abbasov küçəsi...  05 Fevral 2021   7 / 14   \n",
       "3  Masazır qəsəbəsi, Yeni Bakı yaşayış kompleksi ...  05 Fevral 2021    4 / 8   \n",
       "4  Tecili satilir !!\\n4 cu mikrorayonda, Elmed kl...  05 Fevral 2021  12 / 18   \n",
       "\n",
       "   ... Distance_to_Elmlar Akademiyası  Distance_to_Inshaatchilar  \\\n",
       "0  ...                       4.160858                   4.286099   \n",
       "1  ...                       3.641406                   4.332380   \n",
       "2  ...                       3.581641                   5.582994   \n",
       "3  ...                      14.206736                  12.227296   \n",
       "4  ...                       4.673150                   3.024011   \n",
       "\n",
       "  Distance_to_20 Yanvar Distance_to_Memar Ajami Distance_to_Nasimi  \\\n",
       "0              3.743220                3.426369           3.526779   \n",
       "1              4.231128                4.144856           4.607402   \n",
       "2              6.768512                7.300160           8.641321   \n",
       "3             11.026164               10.643766           9.980590   \n",
       "4              1.442451                0.755332           1.520455   \n",
       "\n",
       "   Distance_to_Azadlig Prospekti  Distance_to_Darnagul  \\\n",
       "0                       3.003716              2.935154   \n",
       "1                       4.205311              4.055194   \n",
       "2                       8.760267              8.923853   \n",
       "3                      10.854980             12.221727   \n",
       "4                       2.857948              4.475584   \n",
       "\n",
       "  Distance_to_Jafar Jabbarli  Distance_to_Shah Ismail Hatai  \\\n",
       "0                   2.290520                       2.572313   \n",
       "1                   1.151950                       1.703825   \n",
       "2                   3.735953                       4.969501   \n",
       "3                  15.191301                      16.077384   \n",
       "4                   5.308145                       6.452175   \n",
       "\n",
       "   Distance_to_Avtovagzal  \n",
       "0                5.369413  \n",
       "1                6.151793  \n",
       "2                9.007009  \n",
       "3                8.774474  \n",
       "4                1.403696  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from geopy.distance import geodesic\n",
    "\n",
    "# distances = {}\n",
    "\n",
    "# for index, place in baku_coordinates.iterrows():\n",
    "#     place_name = place['Title']\n",
    "#     place_coords = (place['Latitude'], place['Longitude'])\n",
    "    \n",
    "#     distances[place_name] = train_data.apply(\n",
    "#         lambda row: geodesic((row['latitude'], row['longitude']), place_coords).kilometers, axis=1\n",
    "#     )\n",
    "\n",
    "# for place_name, distance_series in distances.items():\n",
    "#     train_data[f'Distance_to_{place_name}'] = distance_series\n",
    "    \n",
    "# for place_name, distance_series in distances.items():\n",
    "#     test_data[f'Distance_to_{place_name}'] = distance_series\n",
    "\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f72235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1493931583.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data['place'] = train_data['title'].apply(lambda x: x.split(',')[-1].strip())\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1493931583.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['place'] = test_data['title'].apply(lambda x: x.split(',')[-1].strip())\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1493931583.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data['place_encoded'] = label_encoder.fit_transform(train_data['place'])\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1493931583.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['place_encoded'] = label_encoder.fit_transform(test_data['place'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1-ci mikrorayon q.': 0,\n",
       " '20 Yanvar m.': 1,\n",
       " '20-ci sahə q.': 2,\n",
       " '28 May m.': 3,\n",
       " '3-cü mikrorayon q.': 4,\n",
       " '4-cü mikrorayon q.': 5,\n",
       " '5-ci mikrorayon q.': 6,\n",
       " '6-cı mikrorayon q.': 7,\n",
       " '7-ci mikrorayon q.': 8,\n",
       " '8-ci kilometr q.': 9,\n",
       " '8-ci mikrorayon q.': 10,\n",
       " '9-cu mikrorayon q.': 11,\n",
       " 'Abşeron r.': 12,\n",
       " 'Avtovağzal m.': 13,\n",
       " 'Azadlıq Prospekti m.': 14,\n",
       " 'Badamdar q.': 15,\n",
       " 'Bakmil m.': 16,\n",
       " 'Bakıxanov q.': 17,\n",
       " 'Bayıl q.': 18,\n",
       " 'Biləcəri q.': 19,\n",
       " 'Binə q.': 20,\n",
       " 'Binəqədi q.': 21,\n",
       " 'Binəqədi r.': 22,\n",
       " 'Buzovna q.': 23,\n",
       " 'Böyükşor q.': 24,\n",
       " 'Ceyranbatan q.': 25,\n",
       " 'Digah q.': 26,\n",
       " 'Dərnəgül m.': 27,\n",
       " 'Elmlər Akademiyası m.': 28,\n",
       " 'Günəşli q.': 29,\n",
       " 'Gənclik m.': 30,\n",
       " 'Hökməli q.': 31,\n",
       " 'Hövsan q.': 32,\n",
       " 'Həzi Aslanov m.': 33,\n",
       " 'Həzi Aslanov q.': 34,\n",
       " 'Koroğlu m.': 35,\n",
       " 'Kubinka q.': 36,\n",
       " 'Köhnə Günəşli q.': 37,\n",
       " 'Lökbatan q.': 38,\n",
       " 'M.Ə.Rəsulzadə q.': 39,\n",
       " 'Masazır q.': 40,\n",
       " 'Massiv A q.': 41,\n",
       " 'Massiv D q.': 42,\n",
       " 'Massiv V q.': 43,\n",
       " 'Mehdiabad q.': 44,\n",
       " 'Memar Əcəmi m.': 45,\n",
       " 'Məmmədli q.': 46,\n",
       " 'Mərdəkan q.': 47,\n",
       " 'Nardaran q.': 48,\n",
       " 'Neftçilər m.': 49,\n",
       " 'Nizami m.': 50,\n",
       " 'Nizami r.': 51,\n",
       " 'Novxanı q.': 52,\n",
       " 'Nəriman Nərimanov m.': 53,\n",
       " 'Nərimanov r.': 54,\n",
       " 'Nəsimi m.': 55,\n",
       " 'Nəsimi r.': 56,\n",
       " 'Qala q.': 57,\n",
       " 'Qara Qarayev m.': 58,\n",
       " 'Qaradağ r.': 59,\n",
       " 'Qaraçuxur q.': 60,\n",
       " 'Sabunçu q.': 61,\n",
       " 'Sabunçu r.': 62,\n",
       " 'Sahil m.': 63,\n",
       " 'Sahil q.': 64,\n",
       " 'Saray q.': 65,\n",
       " 'Sulutəpə q.': 66,\n",
       " 'Sumqayıt': 67,\n",
       " 'Suraxanı q.': 68,\n",
       " 'Suraxanı r.': 69,\n",
       " 'Səbail r.': 70,\n",
       " 'Türkan q.': 71,\n",
       " 'Xalqlar Dostluğu m.': 72,\n",
       " 'Xocəsən q.': 73,\n",
       " 'Xutor q.': 74,\n",
       " 'Xırdalan': 75,\n",
       " 'Xətai r.': 76,\n",
       " 'Xəzər r.': 77,\n",
       " 'Yasamal q.': 78,\n",
       " 'Yasamal r.': 79,\n",
       " 'Yeni Corat q.': 80,\n",
       " 'Yeni Günəşli q.': 81,\n",
       " 'Yeni Ramana q.': 82,\n",
       " 'Yeni Suraxanı q.': 83,\n",
       " 'Yeni Yasamal q.': 84,\n",
       " 'Zabrat q.': 85,\n",
       " 'Zığ q.': 86,\n",
       " 'İnşaatçılar m.': 87,\n",
       " 'İçəri Şəhər m.': 88,\n",
       " 'Şah İsmayıl Xətai m.': 89,\n",
       " 'Şahbuz r.': 90,\n",
       " 'Əhmədli m.': 91,\n",
       " 'Əhmədli q.': 92,\n",
       " 'Абшеронcкий  р.': 93,\n",
       " 'Бинагадинский р.': 94,\n",
       " 'Наримановский  р.': 95,\n",
       " 'Насиминский  р.': 96,\n",
       " 'Низаминский  р.': 97,\n",
       " 'Сабаильский р.': 98,\n",
       " 'Сумгаит': 99,\n",
       " 'Сураханский  р.': 100,\n",
       " 'Хатаинский р.': 101,\n",
       " 'Хырдалан': 102,\n",
       " 'Ясамальский р.': 103,\n",
       " 'м. 20 января': 104,\n",
       " 'м. 28 мая': 105,\n",
       " 'м. Автовокзал': 106,\n",
       " 'м. Азадлыг проспекти': 107,\n",
       " 'м. Ази Асланов': 108,\n",
       " 'м. Ахмедлы': 109,\n",
       " 'м. Бакмил': 110,\n",
       " 'м. Гянджлик': 111,\n",
       " 'м. Дернегюль': 112,\n",
       " 'м. Иншаатчылар': 113,\n",
       " 'м. Ичеришехер': 114,\n",
       " 'м. Кара Караев': 115,\n",
       " 'м. Мемар Аджеми': 116,\n",
       " 'м. Нариман Нариманов': 117,\n",
       " 'м. Насими': 118,\n",
       " 'м. Нефтчиляр': 119,\n",
       " 'м. Низами': 120,\n",
       " 'м. Сахил': 121,\n",
       " 'м. Халглар Достлугу': 122,\n",
       " 'м. Шах Исмаил Хатаи': 123,\n",
       " 'м. Элмляр Академиясы': 124,\n",
       " 'пос. 20-й участок': 125,\n",
       " 'пос. 3-й мкр': 126,\n",
       " 'пос. 4-й мкр': 127,\n",
       " 'пос. 5-й мкр': 128,\n",
       " 'пос. 7-ой мкр': 129,\n",
       " 'пос. 8-й километр': 130,\n",
       " 'пос. 8-й мкр': 131,\n",
       " 'пос. 9-й мкр': 132,\n",
       " 'пос. Ази Асланова': 133,\n",
       " 'пос. Ахмедлы': 134,\n",
       " 'пос. Бадамдар': 135,\n",
       " 'пос. Баилова': 136,\n",
       " 'пос. Бакиханова': 137,\n",
       " 'пос. Биладжары': 138,\n",
       " 'пос. Бинагади': 139,\n",
       " 'пос. Ени Гюнешли': 140,\n",
       " 'пос. Ени Ясамал': 141,\n",
       " 'пос. Забрат': 142,\n",
       " 'пос. Карачухур': 143,\n",
       " 'пос. Локбатан': 144,\n",
       " 'пос. М. Расулзаде': 145,\n",
       " 'пос. Мамедли': 146,\n",
       " 'пос. Масазыр': 147,\n",
       " 'пос. Массив А': 148,\n",
       " 'пос. Старые Гюнешли': 149,\n",
       " 'пос. Хутор': 150,\n",
       " 'пос. Ясамал': 151}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data['place'] = train_data['title'].apply(lambda x: x.split(',')[-1].strip())\n",
    "# test_data['place'] = test_data['title'].apply(lambda x: x.split(',')[-1].strip())\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# train_data['place_encoded'] = label_encoder.fit_transform(train_data['place'])\n",
    "# test_data['place_encoded'] = label_encoder.fit_transform(test_data['place'])\n",
    "\n",
    "# place_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "# place_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457e46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421a599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>price_currency</th>\n",
       "      <th>poster</th>\n",
       "      <th>poster_type</th>\n",
       "      <th>Ünvan</th>\n",
       "      <th>description</th>\n",
       "      <th>Yeniləndi</th>\n",
       "      <th>Mərtəbə</th>\n",
       "      <th>...</th>\n",
       "      <th>Distance_to_20 Yanvar</th>\n",
       "      <th>Distance_to_Memar Ajami</th>\n",
       "      <th>Distance_to_Nasimi</th>\n",
       "      <th>Distance_to_Azadlig Prospekti</th>\n",
       "      <th>Distance_to_Darnagul</th>\n",
       "      <th>Distance_to_Jafar Jabbarli</th>\n",
       "      <th>Distance_to_Shah Ismail Hatai</th>\n",
       "      <th>Distance_to_Avtovagzal</th>\n",
       "      <th>place</th>\n",
       "      <th>place_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Satılır 3 otaqlı yeni tikili 135 m², Gənclik m.</td>\n",
       "      <td>300000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Mubariz</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Bakıxanov  küçəsi</td>\n",
       "      <td>Təcili  Satılır...Qaz  Kupça  var..\\nRoseville...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>5 / 17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.743220</td>\n",
       "      <td>3.426369</td>\n",
       "      <td>3.526779</td>\n",
       "      <td>3.003716</td>\n",
       "      <td>2.935154</td>\n",
       "      <td>2.290520</td>\n",
       "      <td>2.572313</td>\n",
       "      <td>5.369413</td>\n",
       "      <td>Gənclik m.</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Satılır 3 otaqlı yeni tikili 132.5 m², Nəriman...</td>\n",
       "      <td>153000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Самир Ахмедов</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, ул.Табриза 21-23</td>\n",
       "      <td>Срочно.В Наримановском р-не недалеко от 162 шк...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>10 / 16</td>\n",
       "      <td>...</td>\n",
       "      <td>4.231128</td>\n",
       "      <td>4.144856</td>\n",
       "      <td>4.607402</td>\n",
       "      <td>4.205311</td>\n",
       "      <td>4.055194</td>\n",
       "      <td>1.151950</td>\n",
       "      <td>1.703825</td>\n",
       "      <td>6.151793</td>\n",
       "      <td>Nərimanov r.</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 115 m², Bayıl q.</td>\n",
       "      <td>171300</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Fikrət</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Q.Abbasov küçəsi</td>\n",
       "      <td>Səbail rayonu ,Bayıl qəsəbəsi Q.Abbasov küçəsi...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>7 / 14</td>\n",
       "      <td>...</td>\n",
       "      <td>6.768512</td>\n",
       "      <td>7.300160</td>\n",
       "      <td>8.641321</td>\n",
       "      <td>8.760267</td>\n",
       "      <td>8.923853</td>\n",
       "      <td>3.735953</td>\n",
       "      <td>4.969501</td>\n",
       "      <td>9.007009</td>\n",
       "      <td>Bayıl q.</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 43 m², Masazır q.</td>\n",
       "      <td>44500</td>\n",
       "      <td>AZN</td>\n",
       "      <td>QASIM</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, İstiqlaliyyət 14</td>\n",
       "      <td>Masazır qəsəbəsi, Yeni Bakı yaşayış kompleksi ...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>4 / 8</td>\n",
       "      <td>...</td>\n",
       "      <td>11.026164</td>\n",
       "      <td>10.643766</td>\n",
       "      <td>9.980590</td>\n",
       "      <td>10.854980</td>\n",
       "      <td>12.221727</td>\n",
       "      <td>15.191301</td>\n",
       "      <td>16.077384</td>\n",
       "      <td>8.774474</td>\n",
       "      <td>Masazır q.</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 65 m², Memar Əcəm...</td>\n",
       "      <td>89900</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Heydər bəy</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Mir Cəlal küç.</td>\n",
       "      <td>Tecili satilir !!\\n4 cu mikrorayonda, Elmed kl...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>12 / 18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.442451</td>\n",
       "      <td>0.755332</td>\n",
       "      <td>1.520455</td>\n",
       "      <td>2.857948</td>\n",
       "      <td>4.475584</td>\n",
       "      <td>5.308145</td>\n",
       "      <td>6.452175</td>\n",
       "      <td>1.403696</td>\n",
       "      <td>Memar Əcəmi m.</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95</td>\n",
       "      <td>Satılır 1 otaqlı yeni tikili 55 m², Xətai r.</td>\n",
       "      <td>46000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Rəsul</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Sadiqcan kuçəsi  32</td>\n",
       "      <td>Həzi Aslanov metrosunun yaxinliginda,Elita res...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>12 / 16</td>\n",
       "      <td>...</td>\n",
       "      <td>13.224176</td>\n",
       "      <td>13.040195</td>\n",
       "      <td>12.911907</td>\n",
       "      <td>11.839470</td>\n",
       "      <td>10.461350</td>\n",
       "      <td>9.069763</td>\n",
       "      <td>7.302788</td>\n",
       "      <td>14.995141</td>\n",
       "      <td>Xətai r.</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128</td>\n",
       "      <td>Satılır 3 otaqlı yeni tikili 115 m², Həzi Asla...</td>\n",
       "      <td>142000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Emin</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, M.Hadi küçəsi</td>\n",
       "      <td>Xətai rayonu, Əhmədli qəsəbəsi, Həzi Aslanov m...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>11 / 17</td>\n",
       "      <td>...</td>\n",
       "      <td>12.789199</td>\n",
       "      <td>12.535556</td>\n",
       "      <td>12.263260</td>\n",
       "      <td>11.121753</td>\n",
       "      <td>9.666130</td>\n",
       "      <td>8.820633</td>\n",
       "      <td>6.949939</td>\n",
       "      <td>14.449961</td>\n",
       "      <td>Həzi Aslanov m.</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>133</td>\n",
       "      <td>Satılır 4 otaqlı yeni tikili 192 m², Elmlər Ak...</td>\n",
       "      <td>235000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Paşa</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Mətbuat pr. 5.</td>\n",
       "      <td>TƏCİLİ!!! TƏCİLİ!!! TƏCİLİ!!!\\nƏlimyandi varia...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>14 / 14</td>\n",
       "      <td>...</td>\n",
       "      <td>3.174834</td>\n",
       "      <td>3.916287</td>\n",
       "      <td>5.618099</td>\n",
       "      <td>6.262112</td>\n",
       "      <td>7.115750</td>\n",
       "      <td>3.436024</td>\n",
       "      <td>5.401775</td>\n",
       "      <td>5.287251</td>\n",
       "      <td>Elmlər Akademiyası m.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 63 m², Yasamal r.</td>\n",
       "      <td>88000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>İbrahim bey</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Dadaş Bünyatzadə küç.</td>\n",
       "      <td>SUN ESTATE dasinmaz emalk sirketi teklif edir!...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>7 / 12</td>\n",
       "      <td>...</td>\n",
       "      <td>2.628699</td>\n",
       "      <td>3.468855</td>\n",
       "      <td>5.276124</td>\n",
       "      <td>6.123951</td>\n",
       "      <td>7.191390</td>\n",
       "      <td>4.197798</td>\n",
       "      <td>6.127636</td>\n",
       "      <td>4.538211</td>\n",
       "      <td>Yasamal r.</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63</td>\n",
       "      <td>Satılır 2 otaqlı yeni tikili 107 m², Elmlər Ak...</td>\n",
       "      <td>235000</td>\n",
       "      <td>AZN</td>\n",
       "      <td>Hebib</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>Bakı şəhəri, Hüseyn Cavid pr.</td>\n",
       "      <td>YASAMAL rayonu. Hüseyin Cavid praspektində. Kİ...</td>\n",
       "      <td>05 Fevral 2021</td>\n",
       "      <td>15 / 20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.755928</td>\n",
       "      <td>3.412097</td>\n",
       "      <td>5.035847</td>\n",
       "      <td>5.605244</td>\n",
       "      <td>6.418057</td>\n",
       "      <td>2.900172</td>\n",
       "      <td>4.842675</td>\n",
       "      <td>4.962802</td>\n",
       "      <td>Elmlər Akademiyası m.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id                                              title   price  \\\n",
       "0    6    Satılır 3 otaqlı yeni tikili 135 m², Gənclik m.  300000   \n",
       "1   22  Satılır 3 otaqlı yeni tikili 132.5 m², Nəriman...  153000   \n",
       "2   72      Satılır 2 otaqlı yeni tikili 115 m², Bayıl q.  171300   \n",
       "3   76     Satılır 2 otaqlı yeni tikili 43 m², Masazır q.   44500   \n",
       "4   86  Satılır 2 otaqlı yeni tikili 65 m², Memar Əcəm...   89900   \n",
       "5   95       Satılır 1 otaqlı yeni tikili 55 m², Xətai r.   46000   \n",
       "6  128  Satılır 3 otaqlı yeni tikili 115 m², Həzi Asla...  142000   \n",
       "7  133  Satılır 4 otaqlı yeni tikili 192 m², Elmlər Ak...  235000   \n",
       "8   60     Satılır 2 otaqlı yeni tikili 63 m², Yasamal r.   88000   \n",
       "9   63  Satılır 2 otaqlı yeni tikili 107 m², Elmlər Ak...  235000   \n",
       "\n",
       "  price_currency         poster       poster_type  \\\n",
       "0            AZN        Mubariz  vasitəçi (agent)   \n",
       "1            AZN  Самир Ахмедов  vasitəçi (agent)   \n",
       "2            AZN         Fikrət  vasitəçi (agent)   \n",
       "3            AZN          QASIM  vasitəçi (agent)   \n",
       "4            AZN     Heydər bəy  vasitəçi (agent)   \n",
       "5            AZN          Rəsul  vasitəçi (agent)   \n",
       "6            AZN           Emin  vasitəçi (agent)   \n",
       "7            AZN           Paşa  vasitəçi (agent)   \n",
       "8            AZN    İbrahim bey  vasitəçi (agent)   \n",
       "9            AZN         Hebib   vasitəçi (agent)   \n",
       "\n",
       "                                 Ünvan  \\\n",
       "0     Bakı şəhəri, Bakıxanov  küçəsi     \n",
       "1        Bakı şəhəri, ул.Табриза 21-23   \n",
       "2        Bakı şəhəri, Q.Abbasov küçəsi   \n",
       "3        Bakı şəhəri, İstiqlaliyyət 14   \n",
       "4          Bakı şəhəri, Mir Cəlal küç.   \n",
       "5     Bakı şəhəri, Sadiqcan kuçəsi  32   \n",
       "6           Bakı şəhəri, M.Hadi küçəsi   \n",
       "7          Bakı şəhəri, Mətbuat pr. 5.   \n",
       "8   Bakı şəhəri, Dadaş Bünyatzadə küç.   \n",
       "9        Bakı şəhəri, Hüseyn Cavid pr.   \n",
       "\n",
       "                                         description       Yeniləndi  Mərtəbə  \\\n",
       "0  Təcili  Satılır...Qaz  Kupça  var..\\nRoseville...  05 Fevral 2021   5 / 17   \n",
       "1  Срочно.В Наримановском р-не недалеко от 162 шк...  05 Fevral 2021  10 / 16   \n",
       "2  Səbail rayonu ,Bayıl qəsəbəsi Q.Abbasov küçəsi...  05 Fevral 2021   7 / 14   \n",
       "3  Masazır qəsəbəsi, Yeni Bakı yaşayış kompleksi ...  05 Fevral 2021    4 / 8   \n",
       "4  Tecili satilir !!\\n4 cu mikrorayonda, Elmed kl...  05 Fevral 2021  12 / 18   \n",
       "5  Həzi Aslanov metrosunun yaxinliginda,Elita res...  05 Fevral 2021  12 / 16   \n",
       "6  Xətai rayonu, Əhmədli qəsəbəsi, Həzi Aslanov m...  05 Fevral 2021  11 / 17   \n",
       "7  TƏCİLİ!!! TƏCİLİ!!! TƏCİLİ!!!\\nƏlimyandi varia...  05 Fevral 2021  14 / 14   \n",
       "8  SUN ESTATE dasinmaz emalk sirketi teklif edir!...  05 Fevral 2021   7 / 12   \n",
       "9  YASAMAL rayonu. Hüseyin Cavid praspektində. Kİ...  05 Fevral 2021  15 / 20   \n",
       "\n",
       "   ... Distance_to_20 Yanvar  Distance_to_Memar Ajami Distance_to_Nasimi  \\\n",
       "0  ...              3.743220                 3.426369           3.526779   \n",
       "1  ...              4.231128                 4.144856           4.607402   \n",
       "2  ...              6.768512                 7.300160           8.641321   \n",
       "3  ...             11.026164                10.643766           9.980590   \n",
       "4  ...              1.442451                 0.755332           1.520455   \n",
       "5  ...             13.224176                13.040195          12.911907   \n",
       "6  ...             12.789199                12.535556          12.263260   \n",
       "7  ...              3.174834                 3.916287           5.618099   \n",
       "8  ...              2.628699                 3.468855           5.276124   \n",
       "9  ...              2.755928                 3.412097           5.035847   \n",
       "\n",
       "  Distance_to_Azadlig Prospekti Distance_to_Darnagul  \\\n",
       "0                      3.003716             2.935154   \n",
       "1                      4.205311             4.055194   \n",
       "2                      8.760267             8.923853   \n",
       "3                     10.854980            12.221727   \n",
       "4                      2.857948             4.475584   \n",
       "5                     11.839470            10.461350   \n",
       "6                     11.121753             9.666130   \n",
       "7                      6.262112             7.115750   \n",
       "8                      6.123951             7.191390   \n",
       "9                      5.605244             6.418057   \n",
       "\n",
       "   Distance_to_Jafar Jabbarli  Distance_to_Shah Ismail Hatai  \\\n",
       "0                    2.290520                       2.572313   \n",
       "1                    1.151950                       1.703825   \n",
       "2                    3.735953                       4.969501   \n",
       "3                   15.191301                      16.077384   \n",
       "4                    5.308145                       6.452175   \n",
       "5                    9.069763                       7.302788   \n",
       "6                    8.820633                       6.949939   \n",
       "7                    3.436024                       5.401775   \n",
       "8                    4.197798                       6.127636   \n",
       "9                    2.900172                       4.842675   \n",
       "\n",
       "  Distance_to_Avtovagzal                  place  place_encoded  \n",
       "0               5.369413             Gənclik m.             36  \n",
       "1               6.151793           Nərimanov r.             63  \n",
       "2               9.007009               Bayıl q.             22  \n",
       "3               8.774474             Masazır q.             46  \n",
       "4               1.403696         Memar Əcəmi m.             52  \n",
       "5              14.995141               Xətai r.             90  \n",
       "6              14.449961        Həzi Aslanov m.             39  \n",
       "7               5.287251  Elmlər Akademiyası m.             33  \n",
       "8               4.538211             Yasamal r.             93  \n",
       "9               4.962802  Elmlər Akademiyası m.             33  \n",
       "\n",
       "[10 rows x 150 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046ebef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Kupça'].fillna(train_data['Kupça'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f98dc067",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Kupça'] = train_data['Kupça'].astype('category').cat.codes\n",
    "test_data['Kupça'] = test_data['Kupça'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429cfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['description'] = train_data['description'].str.lower()\n",
    "test_data['description'] = test_data['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60dacabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/886240855.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "def add_keyword_features(df, words_to_check, new_col_name):\n",
    "    pattern = r'\\b(?:' + '|'.join(words_to_check) + r')\\b'\n",
    "    df[new_col_name] = df['description'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
    "\n",
    "keywords = {\n",
    "    'urgent': [\"təcili\", \"срочно\", \"tecili\", \"tacili\"],\n",
    "    'wifi': [\"wifi\", \"internet\", \"vayfay\"],\n",
    "    'vip': [\"vip\"],\n",
    "    'garage': [\"гараж\", \"qaraj\"],\n",
    "    'premium': [\"premium\", \"premiyum\"],\n",
    "    'furnished': [\"temirli\", \"təmirli\"],\n",
    "    'school': [\"mekteb\", \"məktəb\"],\n",
    "    'university': [\"uni\", \"universitet\", \"akademiya\"],\n",
    "    'metro': [\"metro\"],\n",
    "    'esyali': [\"əşyalı\", \"esyali\"],\n",
    "    'esyasiz': [\"əşyasız\", \"esyasiz\"],\n",
    "    'geniş': [\"genis\", \"geniş\"],\n",
    "    'mühafizə': [\"mühafizə\"],\n",
    "    'park': [\"park\"],\n",
    "    'water': [\"su\"],\n",
    "    'gas': [\"qaz\"],\n",
    "    'electricity': [\"isiq\", \"isıq\", \"işıq\", \"elektrik\"],\n",
    "    'kombi': [\"kombi\", \"istilik sistemi\"],\n",
    "    'genis': [\"genis\", \"geniş\"],\n",
    "    '!s': [\"!!!\", \"!!!!\"]\n",
    "    \n",
    "}\n",
    "\n",
    "for key, words in keywords.items():\n",
    "    add_keyword_features(train_data, words, key)\n",
    "    add_keyword_features(test_data, words, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb4e450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1743821273.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data['yeni_tikili'] = train_data['title'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1743821273.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['yeni_tikili'] = test_data['title'].str.contains(pattern, case=False).fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "words_to_check = [\"yeni tikili\"]  \n",
    "\n",
    "train_data['title'] = train_data['title'].str.lower()\n",
    "test_data['title'] = test_data['title'].str.lower()\n",
    "\n",
    "pattern = r'\\b(?:' + '|'.join(words_to_check) + r')\\b'\n",
    "\n",
    "train_data['yeni_tikili'] = train_data['title'].str.contains(pattern, case=False).fillna(0).astype(int)\n",
    "test_data['yeni_tikili'] = test_data['title'].str.contains(pattern, case=False).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba598f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_to_count = 'bağ evi'\n",
    "\n",
    "# # Count occurrences of the word in the description column\n",
    "# word_occurrences = train_data['description'].str.lower().str.count(word_to_count)\n",
    "\n",
    "# # Calculate the total occurrences of the word\n",
    "# total_word_occurrences = word_occurrences.sum()\n",
    "\n",
    "# # Print the result\n",
    "# print(f\"The word '{word_to_count}' appears {total_word_occurrences} times in the descriptions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dba469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796b4288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common phrases (up to 2 words):\n",
      "'və' is used 69241 times\n",
      "'mənzil' is used 46067 times\n",
      "'2' is used 45498 times\n",
      "'3' is used 36096 times\n",
      "'yeni' is used 32115 times\n",
      "'var.' is used 29728 times\n",
      "'menzil' is used 26610 times\n",
      "'binanın' is used 26486 times\n",
      "'olan' is used 25137 times\n",
      "',' is used 21576 times\n",
      "'satılır.' is used 20948 times\n",
      "'mərtəbəli' is used 20940 times\n",
      "'ve' is used 20549 times\n",
      "'-' is used 19826 times\n",
      "'binada' is used 19601 times\n",
      "'sahəsi' is used 18377 times\n",
      "'üçün' is used 17866 times\n",
      "'tam' is used 17523 times\n",
      "'в' is used 16824 times\n",
      "'1' is used 16732 times\n",
      "'и' is used 16684 times\n",
      "'otaqlı' is used 16259 times\n",
      "'yaşayış' is used 16222 times\n",
      "'mərtəbəsində' is used 15695 times\n",
      "'ilə' is used 15497 times\n",
      "'qaz' is used 15426 times\n",
      "'tikili' is used 15212 times\n",
      "'geniş' is used 15121 times\n",
      "'var' is used 15027 times\n",
      "'mənzil satılır.' is used 14946 times\n",
      "'saat' is used 14710 times\n",
      "'bina' is used 14672 times\n",
      "'yeni tikili' is used 14602 times\n",
      "'binanin' is used 14498 times\n",
      "'24' is used 14427 times\n",
      "'sistemi' is used 14190 times\n",
      "'təmirli' is used 13936 times\n",
      "'.' is used 13104 times\n",
      "'24 saat' is used 12514 times\n",
      "'4' is used 12169 times\n",
      "'с' is used 12067 times\n",
      "'ümumi' is used 11730 times\n",
      "'otaqli' is used 11345 times\n",
      "'super' is used 11250 times\n",
      "'mənzilin' is used 11070 times\n",
      "'su' is used 11048 times\n",
      "'kv' is used 11044 times\n",
      "'əla' is used 10918 times\n",
      "'uşaq' is used 10847 times\n",
      "'bir' is used 10553 times\n",
      "'!!!' is used 10270 times\n",
      "'ümumi sahəsi' is used 10181 times\n",
      "'mertebesinde' is used 10110 times\n",
      "'mertebeli' is used 10068 times\n",
      "'çox' is used 9967 times\n",
      "'temirli' is used 9760 times\n",
      "'satilir' is used 9729 times\n",
      "'real' is used 9721 times\n",
      "'yasamal' is used 9066 times\n",
      "'satilir.' is used 9003 times\n",
      "'mühafizə' is used 8990 times\n",
      "'mərtəbəli binanın' is used 8965 times\n",
      "'tecili' is used 8958 times\n",
      "'ucun' is used 8797 times\n",
      "'yeraltı' is used 8736 times\n",
      "'!' is used 8687 times\n",
      "'rayonu' is used 8566 times\n",
      "'квартира' is used 8548 times\n",
      "'cox' is used 8434 times\n",
      "'sürətli' is used 8378 times\n",
      "'yerləşir.' is used 8218 times\n",
      "'на' is used 8066 times\n",
      "'təmirli mənzil' is used 8048 times\n",
      "'1%' is used 7963 times\n",
      "'istilik' is used 7919 times\n",
      "'otaq' is used 7884 times\n",
      "'qaz,' is used 7732 times\n",
      "'rayonu,' is used 7715 times\n",
      "'əlaqə' is used 7709 times\n",
      "'metrosunun' is used 7645 times\n",
      "'sahesi' is used 7464 times\n",
      "'ci' is used 7234 times\n",
      "'daimidir.' is used 7187 times\n",
      "'işıq' is used 7105 times\n",
      "'su,' is used 7095 times\n",
      "'gözəl' is used 7056 times\n",
      "'3 otaqlı' is used 7056 times\n",
      "'məlumat' is used 7046 times\n",
      "'haqqi' is used 6988 times\n",
      "'olunub.' is used 6988 times\n",
      "'təmir' is used 6942 times\n",
      "'bütün' is used 6914 times\n",
      "'otaqdan' is used 6829 times\n",
      "'sonra' is used 6803 times\n",
      "'təcili' is used 6691 times\n",
      "'yerləşən' is used 6571 times\n",
      "'yüksək' is used 6562 times\n",
      "'17' is used 6503 times\n",
      "'yaxın' is used 6488 times\n",
      "'saxlaya' is used 6480 times\n",
      "      Phrase  Count\n",
      "0         və  69241\n",
      "1     mənzil  46067\n",
      "2          2  45498\n",
      "3          3  36096\n",
      "4       yeni  32115\n",
      "..       ...    ...\n",
      "95  yerləşən   6571\n",
      "96    yüksək   6562\n",
      "97        17   6503\n",
      "98     yaxın   6488\n",
      "99   saxlaya   6480\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_most_common_phrases(descriptions, max_words=2, top_n=100):\n",
    "    phrases = []\n",
    "    for description in descriptions:\n",
    "        if isinstance(description, str):\n",
    "            words = description.split()\n",
    "            for i in range(len(words)):\n",
    "                for j in range(1, max_words + 1):\n",
    "                    if i + j <= len(words):\n",
    "                        phrase = ' '.join(words[i:i + j])\n",
    "                        phrases.append(phrase.lower())\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "    # Count the occurrences of each phrase\n",
    "    phrase_counts = Counter(phrases)\n",
    "\n",
    "    # Get the top_n most common phrases\n",
    "    most_common_phrases = phrase_counts.most_common(top_n)\n",
    "\n",
    "    return most_common_phrases\n",
    "\n",
    "# Example DataFrame with a 'description' column (replace this with your actual DataFrame)\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Ensure descriptions are treated as strings and handle NaN values\n",
    "train_data['description'] = train_data['description'].fillna('').astype(str)\n",
    "\n",
    "# Get the most common 2-word phrases\n",
    "most_common_phrases = get_most_common_phrases(train_data['description'], max_words=2, top_n=100)\n",
    "\n",
    "print(\"Most common phrases (up to 2 words):\")\n",
    "for phrase, count in most_common_phrases:\n",
    "    print(f\"'{phrase}' is used {count} times\")\n",
    "\n",
    "# If you want to display the result in a dataframe\n",
    "result_df = pd.DataFrame(most_common_phrases, columns=['Phrase', 'Count'])\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f638cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['poster', 'price_currency', 'title', 'locations', 'Ünvan', 'description', 'Yeniləndi', 'place']\n",
    "\n",
    "train_data.drop(columns = columns_to_remove, inplace = True)\n",
    "test_data.drop(columns = columns_to_remove, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b4a84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>price</th>\n",
       "      <th>poster_type</th>\n",
       "      <th>Mərtəbə</th>\n",
       "      <th>Sahə</th>\n",
       "      <th>Otaq sayı</th>\n",
       "      <th>Kupça</th>\n",
       "      <th>İpoteka</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>geniş</th>\n",
       "      <th>mühafizə</th>\n",
       "      <th>park</th>\n",
       "      <th>water</th>\n",
       "      <th>gas</th>\n",
       "      <th>electricity</th>\n",
       "      <th>kombi</th>\n",
       "      <th>genis</th>\n",
       "      <th>!s</th>\n",
       "      <th>yeni_tikili</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>300000</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>5 / 17</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>yoxdur</td>\n",
       "      <td>40.400420</td>\n",
       "      <td>49.851554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>153000</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>10 / 16</td>\n",
       "      <td>132.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>yoxdur</td>\n",
       "      <td>40.389663</td>\n",
       "      <td>49.853717</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>171300</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>7 / 14</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>yoxdur</td>\n",
       "      <td>40.347625</td>\n",
       "      <td>49.836685</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>44500</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>4 / 8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yoxdur</td>\n",
       "      <td>40.492294</td>\n",
       "      <td>49.747231</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>89900</td>\n",
       "      <td>vasitəçi (agent)</td>\n",
       "      <td>12 / 18</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yoxdur</td>\n",
       "      <td>40.417271</td>\n",
       "      <td>49.810311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id   price       poster_type  Mərtəbə   Sahə  Otaq sayı  Kupça İpoteka  \\\n",
       "0    6  300000  vasitəçi (agent)   5 / 17  135.0          3      0  yoxdur   \n",
       "1   22  153000  vasitəçi (agent)  10 / 16  132.5          3      1  yoxdur   \n",
       "2   72  171300  vasitəçi (agent)   7 / 14  115.0          2      1  yoxdur   \n",
       "3   76   44500  vasitəçi (agent)    4 / 8   43.0          2      0  yoxdur   \n",
       "4   86   89900  vasitəçi (agent)  12 / 18   65.0          2      0  yoxdur   \n",
       "\n",
       "    latitude  longitude  ... geniş  mühafizə  park  water  gas  electricity  \\\n",
       "0  40.400420  49.851554  ...     0         0     0      0    1            0   \n",
       "1  40.389663  49.853717  ...     0         0     0      0    0            0   \n",
       "2  40.347625  49.836685  ...     0         0     0      0    1            0   \n",
       "3  40.492294  49.747231  ...     1         1     0      1    1            1   \n",
       "4  40.417271  49.810311  ...     0         0     0      1    1            1   \n",
       "\n",
       "   kombi  genis  !s  yeni_tikili  \n",
       "0      0      0   0            1  \n",
       "1      0      0   0            1  \n",
       "2      0      0   0            1  \n",
       "3      0      1   0            1  \n",
       "4      1      0   0            1  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_area_to_float(area_str):\n",
    "    return float(re.sub(r'[^\\d.]+', '', area_str))\n",
    "\n",
    "train_data['Sahə'] = train_data['Sahə'].apply(convert_area_to_float)\n",
    "test_data['Sahə'] = test_data['Sahə'].apply(convert_area_to_float)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90de3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['İpoteka'] = train_data['İpoteka'].map({'yoxdur': 0, 'var': 1})\n",
    "test_data['İpoteka'] = test_data['İpoteka'].map({'yoxdur': 0, 'var': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b88e702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/3750895249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[['current_floor', 'total_floors']] = train_data['Mərtəbə'].str.split(' / ', expand = True).astype(float)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/3750895249.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data[['current_floor', 'total_floors']] = train_data['Mərtəbə'].str.split(' / ', expand = True).astype(float)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/3750895249.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[['current_floor', 'total_floors']] = test_data['Mərtəbə'].str.split(' / ', expand = True).astype(float)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/3750895249.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data[['current_floor', 'total_floors']] = test_data['Mərtəbə'].str.split(' / ', expand = True).astype(float)\n"
     ]
    }
   ],
   "source": [
    "train_data[['current_floor', 'total_floors']] = train_data['Mərtəbə'].str.split(' / ', expand = True).astype(float)\n",
    "test_data[['current_floor', 'total_floors']] = test_data['Mərtəbə'].str.split(' / ', expand = True).astype(float)\n",
    "\n",
    "train_data.drop('Mərtəbə', axis = 1, inplace = True)\n",
    "test_data.drop('Mərtəbə', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b93a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/3993994347.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data['capital'] = (train_data['seher'] == 'baki').astype(int)\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/3993994347.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['capital'] = (test_data['seher'] == 'baki').astype(int)\n"
     ]
    }
   ],
   "source": [
    "train_data['capital'] = (train_data['seher'] == 'baki').astype(int)\n",
    "test_data['capital'] = (test_data['seher'] == 'baki').astype(int)\n",
    "train_data = train_data.drop('seher', axis=1) \n",
    "test_data = test_data.drop('seher', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be6fbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['poster_type'] = (train_data['poster_type'] == 'mülkiyyətçi').astype(int)\n",
    "test_data['poster_type'] = (test_data['poster_type'] == 'mülkiyyətçi').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6d0fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/2291381893.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data['floor_ratio'] = train_data['current_floor'] / train_data['total_floors']\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/2291381893.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['floor_ratio'] = test_data['current_floor'] / test_data['total_floors']\n"
     ]
    }
   ],
   "source": [
    "train_data['floor_ratio'] = train_data['current_floor'] / train_data['total_floors']\n",
    "test_data['floor_ratio'] = test_data['current_floor'] / test_data['total_floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16b66c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>price</th>\n",
       "      <th>poster_type</th>\n",
       "      <th>Sahə</th>\n",
       "      <th>Otaq sayı</th>\n",
       "      <th>Kupça</th>\n",
       "      <th>İpoteka</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Distance_to_Abşeron Milli Parkı</th>\n",
       "      <th>...</th>\n",
       "      <th>water</th>\n",
       "      <th>gas</th>\n",
       "      <th>electricity</th>\n",
       "      <th>kombi</th>\n",
       "      <th>genis</th>\n",
       "      <th>!s</th>\n",
       "      <th>yeni_tikili</th>\n",
       "      <th>current_floor</th>\n",
       "      <th>capital</th>\n",
       "      <th>floor_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.400420</td>\n",
       "      <td>49.851554</td>\n",
       "      <td>44.312820</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>153000</td>\n",
       "      <td>0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.389663</td>\n",
       "      <td>49.853717</td>\n",
       "      <td>43.802452</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>171300</td>\n",
       "      <td>0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.347625</td>\n",
       "      <td>49.836685</td>\n",
       "      <td>44.217733</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>44500</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.492294</td>\n",
       "      <td>49.747231</td>\n",
       "      <td>56.209794</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>89900</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.417271</td>\n",
       "      <td>49.810311</td>\n",
       "      <td>48.213089</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id   price  poster_type   Sahə  Otaq sayı  Kupça  İpoteka   latitude  \\\n",
       "0    6  300000            0  135.0          3      0        0  40.400420   \n",
       "1   22  153000            0  132.5          3      1        0  40.389663   \n",
       "2   72  171300            0  115.0          2      1        0  40.347625   \n",
       "3   76   44500            0   43.0          2      0        0  40.492294   \n",
       "4   86   89900            0   65.0          2      0        0  40.417271   \n",
       "\n",
       "   longitude  Distance_to_Abşeron Milli Parkı  ...  water  gas  electricity  \\\n",
       "0  49.851554                        44.312820  ...      0    1            0   \n",
       "1  49.853717                        43.802452  ...      0    0            0   \n",
       "2  49.836685                        44.217733  ...      0    1            0   \n",
       "3  49.747231                        56.209794  ...      1    1            1   \n",
       "4  49.810311                        48.213089  ...      1    1            1   \n",
       "\n",
       "   kombi  genis  !s  yeni_tikili  current_floor  capital  floor_ratio  \n",
       "0      0      0   0            1            5.0        1     0.294118  \n",
       "1      0      0   0            1           10.0        1     0.625000  \n",
       "2      0      0   0            1            7.0        1     0.500000  \n",
       "3      0      1   0            1            4.0        1     0.500000  \n",
       "4      1      0   0            1           12.0        1     0.666667  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop(columns=['total_floors'], inplace = True)\n",
    "test_data.drop(columns=['total_floors'], inplace = True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fb07a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[(train_data['Sahə'] > 20) & (train_data['Sahə'] < 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "649cce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['Otaq sayı'] < 10]\n",
    "train_data = train_data[(train_data['price'] > 5000) & (train_data['price'] < 3000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ad995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/1015447131.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data['price_per_room'] = train_data['price'] / train_data['Otaq sayı']\n"
     ]
    }
   ],
   "source": [
    "train_data['price_per_room'] = train_data['price'] / train_data['Otaq sayı']\n",
    "\n",
    "Q1 = train_data['price_per_room'].quantile(0.05)\n",
    "Q3 = train_data['price_per_room'].quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "train_data = train_data[(train_data['price_per_room'] >= lower_bound) & (train_data['price_per_room'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "522b31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers from 'price' and 'Sahə'\n",
    "train_data = remove_outliers_iqr(train_data, 'price')\n",
    "train_data = remove_outliers_iqr(train_data, 'Sahə')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f234ba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/489614253.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_data['area_per_room'] = train_data['Sahə'] / train_data['Otaq sayı']\n",
      "/var/folders/87/7_fp3pyx6n36kxg11wvx2tr80000gn/T/ipykernel_29510/489614253.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_data['area_per_room'] = test_data['Sahə'] / test_data['Otaq sayı']\n"
     ]
    }
   ],
   "source": [
    "train_data['area_per_room'] = train_data['Sahə'] / train_data['Otaq sayı']\n",
    "test_data['area_per_room'] = test_data['Sahə'] / test_data['Otaq sayı']\n",
    "\n",
    "train_data = train_data[(train_data['area_per_room'] > 5) & (train_data['area_per_room'] < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bffaf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7d80a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  37.3s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  37.4s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.8s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  37.4s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  38.9s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  36.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  36.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  35.3s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.2s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.7s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.2s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  43.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  22.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  21.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  44.9s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  37.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  39.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  43.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  44.9s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  37.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.4s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  44.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  21.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  43.4s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  34.9s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.8s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  43.4s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  22.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  43.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  44.8s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.4s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  44.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  21.9s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  42.9s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  44.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  37.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  37.4s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  39.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  34.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.2s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  43.2s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  43.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  43.8s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.0s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  44.8s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  32.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  31.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  31.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  37.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.8s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.7s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "240 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "190 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Applications/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [            nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -8.87336868e+08 -8.81926833e+08 -8.75613752e+08 -8.87120604e+08\n",
      " -8.84531873e+08 -8.78905313e+08 -8.94743925e+08 -8.97441878e+08\n",
      " -8.91437157e+08 -8.95429501e+08 -8.98795849e+08 -8.93759330e+08\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -1.23638753e+09 -1.24565508e+09 -1.23459300e+09 -1.22544365e+09\n",
      " -1.23709304e+09 -1.23151867e+09 -1.22728466e+09 -1.23994493e+09\n",
      " -1.23067503e+09 -1.23039034e+09 -1.24503873e+09 -1.23753114e+09\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -8.95620014e+08 -8.97209078e+08 -8.93555068e+08 -9.00510517e+08\n",
      " -9.02129442e+08 -8.97827282e+08 -9.12145278e+08 -9.09732684e+08\n",
      " -9.03626799e+08 -9.10777356e+08 -9.11363803e+08 -9.06954479e+08\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -8.84531477e+08 -8.82771009e+08 -8.77316581e+08 -8.93628380e+08\n",
      " -8.89255973e+08 -8.84030232e+08 -8.96371570e+08 -8.97343395e+08\n",
      " -8.91605067e+08 -8.97724222e+08 -9.00744354e+08 -8.96663105e+08]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for Random Forest:  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Validation RMSE for Random Forest: 28525.33607083098\n",
      "Test RMSE for Random Forest: 28397.166783937482\n",
      "Test MAE for Random Forest: 19089.819561089305\n",
      "Test R-Squared (R2) for Random Forest: 0.8690955098583895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Best parameters': {'bootstrap': True,\n",
       "  'max_depth': None,\n",
       "  'max_features': 'sqrt',\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 300},\n",
       " 'Validation RMSE': 28525.33607083098,\n",
       " 'Test RMSE': 28397.166783937482,\n",
       " 'Test MAE': 19089.819561089305,\n",
       " 'Test R-Squared': 0.8690955098583895}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop(['price', '_id', 'price_per_room'], axis=1)\n",
    "y = train_data['price']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
    "# rf_param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 5],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# 8100 fits\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_val_predictions = rf_grid.predict(X_val_scaled)\n",
    "rf_rmse = sqrt(mean_squared_error(y_val, rf_val_predictions))\n",
    "\n",
    "print(\"Best parameters found for Random Forest: \", rf_grid.best_params_)\n",
    "print(f\"Validation RMSE for Random Forest: {rf_rmse}\")\n",
    "\n",
    "rf_test_predictions = rf_grid.predict(X_test_scaled)\n",
    "rf_test_rmse = sqrt(mean_squared_error(y_test, rf_test_predictions))\n",
    "rf_test_mae = mean_absolute_error(y_test, rf_test_predictions)\n",
    "rf_test_r_squared = r2_score(y_test, rf_test_predictions)\n",
    "\n",
    "print(f\"Test RMSE for Random Forest: {rf_test_rmse}\")\n",
    "print(f\"Test MAE for Random Forest: {rf_test_mae}\")\n",
    "print(f\"Test R-Squared (R2) for Random Forest: {rf_test_r_squared}\")\n",
    "\n",
    "X_actual_test_scaled = scaler.transform(test_data.drop(['_id'], axis=1))\n",
    "rf_actual_test_predictions = rf_grid.predict(X_actual_test_scaled)\n",
    "\n",
    "# Create submission file\n",
    "rf_submission = pd.DataFrame({\n",
    "    '_id': test_data['_id'],\n",
    "    'price': rf_actual_test_predictions\n",
    "})\n",
    "rf_submission.to_csv('rf_submission.csv', index=False)\n",
    "\n",
    "rf_validation_results = {\n",
    "    \"Best parameters\": rf_grid.best_params_,\n",
    "    \"Validation RMSE\": rf_rmse,\n",
    "    \"Test RMSE\": rf_test_rmse,\n",
    "    \"Test MAE\": rf_test_mae,\n",
    "    \"Test R-Squared\": rf_test_r_squared\n",
    "}\n",
    "\n",
    "rf_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bf16ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.9s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  44.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  37.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  35.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  31.9s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  31.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  37.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  38.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n"
     ]
    }
   ],
   "source": [
    "#  'Validation RMSE': 42193.999828743355,\n",
    "#  'Test RMSE': 38887.415718991426,\n",
    "#  'Test MAE': 20294.554093680123,\n",
    "#  'Test R-Squared': 0.909916234817711}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4005776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac8232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e8555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
